# -*- coding: utf-8 -*-
"""Social Polarization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15q_yKOMB9UF4GCllL5fnM8kVkgpr2Web
"""

import random
import math

import matplotlib.pyplot as plt
import networkx as nx
import numpy
from scipy.stats import linregress, ttest_1samp
from scipy.cluster.vq import kmeans2

random.seed(1)

# define network settings
population = 1000
initial_connections = min([int(0.1 * population), 100])
network_build_passes = 1


def connect(a, b):
  outbound_connections[a].add(b)
  inbound_connections[b].add(a)

def disconnect(a, b):
  outbound_connections[a].remove(b)
  inbound_connections[b].remove(a)


# initialize network
outbound_connections = [set() for indv in range(population)]
inbound_connections = [set() for indv in range(population)]

G = nx.barabasi_albert_graph(population, initial_connections)
for edge in G.edges:
  a, b = edge
  connect(a, b)
  connect(b, a)


# initialize belief states

'''
belief_states = [None] * population
order = sorted(range(population), key=lambda indv: len(inbound_connections[indv]), reverse=True)
for indv in order:
  neighbor_states = [belief_states[i] for i in outbound_connections[indv] if belief_states[i] != None]

  if len(neighbor_states) > 0 and random.random() < 0.6:
    avg = sum(neighbor_states) / len(neighbor_states)
    state = random.randint(70, 130) / 100 * avg
    if state >= 0.5:
      state = 0.5
    elif state <= -0.5:
      state = -0.5
    belief_states[indv] = state
  else:
    sign = -math.copysign(1, sum([s for s in belief_states if s != None]))
    belief_states[indv] = random.randint(20, 50) / 100 * sign
'''

signs = [-1] * int(population / 2) + [1] * int(population / 2)
random.shuffle(signs)
belief_states = [random.randint(20, 50) * signs[i] / 100 for i in range(population)]


next_belief_states = belief_states.copy()


outboxes = [set([(belief_states[i], i)]) for i in range(population)]
next_outboxes = outboxes.copy()


disconnect_threshold = 0.7
follow_threshold = 0.1
reshare_threshold = 0.2

def sorting_algorithm(degrees, indv, other):
  """ sort `other` based on relevance and the degree of `other` analogous to """
  rank = degrees.index(len(inbound_connections[other]))

  diff = abs(belief_states[indv] - belief_states[other])
  if diff <= 0.5:
    return rank
  else:
    return population

def update():
  global outboxes, next_outboxes, belief_states, next_belief_states

  for indv in range(population):
    inbox = []
    #conns = sorted(outbound_connections[indv], key=lambda other: abs(belief_states[other] - belief_states[indv]))
    degrees = sorted([len(inbound_connections[i]) for i in range(population)], reverse=True)
    conns = sorted(outbound_connections[indv], key=lambda other: sorting_algorithm(degrees, indv, other))
    random.shuffle(conns)
    for other in conns:
      inbox += outboxes[other]

    state = belief_states[indv]
    for post in inbox[:int(initial_connections * 0.75)]:
      msg, author = post

      disagreement = abs(msg - state)
      memory = (belief_states[indv] ** 2) / (0.5 ** 2) * disagreement # gut reaction disagreement makes it harder to accept
      assert memory <= 1, f"memory got too big ({memory})"
    
      state = memory * state + (1 - memory) * msg

      if disagreement > disconnect_threshold:
        if author in outbound_connections[indv]:
          disconnect(indv, author)
          #print(indv, "unfollowed", author)
      if disagreement < follow_threshold:
        connect(indv, author)
        #print(indv, "followed", author)
      if disagreement < reshare_threshold and len(next_outboxes[indv]) < 10:
        next_outboxes[indv].add((msg, author))
        #print(indv, "reshared")

    assert abs(state) <= 0.5, "belief state too extreme"

    next_belief_states[indv] = state
    
    confidence = abs(belief_states[indv]) / 0.5

    if random.random() <= confidence:
      next_outboxes[indv].add((next_belief_states[indv], indv))

  belief_states = next_belief_states.copy()
  outboxes = next_outboxes.copy()
  next_outboxes = [set() for i in range(population)]

sim_length = 100
for i in range(sim_length):
  update()
  try:
    if i % (0.1 * sim_length) == 0:
      print(f"{int(100 * i / sim_length)}%", end="")
    elif i % int(0.01 * sim_length) == 0:
      print(".", end="")
  except:
    pass

  
# https://jimgrange.files.wordpress.com/2015/12/ttable.png

num_bins = 20
n, bins, patches = plt.hist(belief_states, num_bins, facecolor='blue', alpha=0.5)
plt.xlabel("belief states")
plt.ylabel("Frequency")
plt.title("Belief State Frequencies")
plt.show()

# measure polarization
left = [s for s in belief_states if s < 0]
right = [s for s in belief_states if s > 0]
leftists = len(left)
rightists = len(right)
left_mean = sum(left) / leftists if leftists > 0 else 0
right_mean = sum(right) / rightists if leftists > 0 else 0

print(f"{abs(((leftists / (population / 2)) * left_mean - (rightists / (population / 2)) * right_mean) * 100)}% polarization")

set_a = range(5)
set_b = range(5, 10)
ttest_1samp(set_a, 2)

# plot power law distribution
degrees = sorted([math.log10(len(inbound_connections[i]) + 1) for i in range(population)], reverse=True)
ranks = range(population)

z = numpy.polyfit(ranks, degrees, 1)
p = numpy.poly1d(z)
plt.plot(ranks, p(ranks),"r--")

r_value = linregress(ranks, degrees)[2]
r2 = r_value ** 2

print("R^2:", r2)

plt.plot(ranks, degrees, "b.")
plt.xlabel("Rank")
plt.ylabel("log(degree)")
plt.title("Degree Distribution")
plt.show()

G = nx.Graph()
G.add_nodes_from(range(population))
edges = set()
cross_edges = set()
for indv, conns in enumerate(outbound_connections):
  for other in conns:
    if (belief_states[indv] < 0 and belief_states[other] > 0) or (belief_states[indv] > 0 and belief_states[other] < 0):
      cross_edges.add((indv, other))
    edges.add((indv, other))
print(len(cross_edges) / len(edges) * 100)


color_map = []
for node in G:
  if belief_states[node] >= 0.3:
    color_map.append('blue')
  elif belief_states[node] <= -0.3:
    color_map.append('red')
  else:
    color_map.append('gray')

def width(edge):
  if edge in cross_edges:
    return 1
  return 1

G.add_edges_from(edges)
plt.title("Network Connections and Belief States")
nx.draw(G, node_color=color_map, pos=nx.spring_layout(G), node_size=5, width=[width(edge) for edge in G.edges()])
plt.show()

"""Show relationship between time and the following:

* polarity
* \# cross edges / # edges
* degree distribution R^2 (maybe)

Also tweak the following:

* network size
* thresholds
* confidence calculation

Even without showing fission/full polarization I should be able to argue that they will occur based on my results.
"""
